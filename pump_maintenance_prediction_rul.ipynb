{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fc6ea2-ee06-4ef7-b281-181897f8ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4b6368-9f0f-4cdc-9078-57b44c28da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/navya/Downloads/rul_hrs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6222f10e-0fe9-4580-8c3a-7de0a7d7a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f2fde5-f20c-41b8-bb70-16230dab22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6428f085-25e9-4fd0-8b6f-acd78541afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: only numeric features\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "# Step 2: Correlation-based feature selection\n",
    "corr = numeric_df.corr()['rul']\n",
    "top_features = corr[corr.abs() > 0.1].index.tolist()\n",
    "top_features.remove('rul')\n",
    "\n",
    "X = numeric_df[top_features]\n",
    "y = numeric_df['rul']\n",
    "\n",
    "# Step 3: Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28b032b-1ae2-4d1f-8952-9d49960e9135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "RandomForest → MAE: 10.3135, RMSE: 27.7187, R²: 0.9849\n",
      "MAPE: 78.98%\n",
      "SMAPE: 9.23%\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Random Forest with Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                    param_grid,\n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate best model\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Safe MAPE calculation (ignore zero targets)\n",
    "non_zero_indices = y_test != 0\n",
    "mape = np.mean(np.abs((y_test[non_zero_indices] - y_pred[non_zero_indices]) / y_test[non_zero_indices])) * 100\n",
    "\n",
    "# SMAPE calculation\n",
    "smape = np.mean(2 * np.abs(y_pred - y_test) / (np.abs(y_test) + np.abs(y_pred) + 1e-8)) * 100  # add small value to avoid division by 0\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"RandomForest → MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"SMAPE: {smape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c502cc4-5140-4dee-817e-1f17876e4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  \n",
    "joblib.dump(best_model, 'rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a31e01-9021-4b8b-85f0-94b4a102678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features selected based on correlation:\n",
      "['sensor_01', 'sensor_02', 'sensor_05', 'sensor_06', 'sensor_07', 'sensor_09', 'sensor_11', 'sensor_13', 'sensor_17', 'sensor_18', 'sensor_24', 'sensor_29', 'sensor_37', 'sensor_39', 'sensor_41']\n",
      "Total number of features used: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Top features selected based on correlation:\")\n",
    "print(top_features)\n",
    "print(\"Total number of features used:\", len(top_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351333b8-5dd0-41a5-83cb-a2ad7ec68a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [\n",
    "    'sensor_01', 'sensor_02', 'sensor_05', 'sensor_06', 'sensor_07',\n",
    "    'sensor_09', 'sensor_11', 'sensor_13', 'sensor_17', 'sensor_18',\n",
    "    'sensor_24', 'sensor_29', 'sensor_37', 'sensor_39', 'sensor_41'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdaed9e7-d35b-4c84-8441-8918fcca6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('selected_features.json', 'w') as f:\n",
    "    json.dump(top_features, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516098e7-d0c8-460e-8cf8-5df48d243118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "RandomForest (All Features) → MAE: 3.0485, RMSE: 9.4948, R²: 0.9982\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Keep only numeric features\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "# Step 2: Separate features and target\n",
    "X = numeric_df.drop(columns=['rul'])  \n",
    "y = numeric_df['rul']\n",
    "\n",
    "# Step 3: Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Random Forest with Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                    param_grid,\n",
    "                    scoring='neg_mean_absolute_error',\n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate best model\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"RandomForest (All Features) → MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7575a242-d30a-4e66-af7f-80a2efc68449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Log-transform training targets (handles small/zero RUL)\n",
    "y_train_log = np.log1p(y_train)  # Equivalent to log(1 + y_train)\n",
    "\n",
    "# Step 2: Grid search on log-transformed targets\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train_log)\n",
    "\n",
    "# Step 3: Predict in log-space and invert\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_log = best_model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # Equivalent to exp(y_pred_log) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8bb651-ea24-4144-8227-4049491794c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "MAE: 13.8896, RMSE: 40.9715, R²: 0.9671\n",
      "WMAPE: 4.84%\n",
      "SMAPE: 6.10%\n"
     ]
    }
   ],
   "source": [
    "# Standard metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# WMAPE: weighted MAPE (avoids division-by-zero & stabilizes small targets)\n",
    "wmape = np.abs(y_test - y_pred).sum() / np.abs(y_test).sum() * 100\n",
    "\n",
    "# SMAPE: symmetric MAPE\n",
    "smape = np.mean(\n",
    "    2 * np.abs(y_pred - y_test) /\n",
    "    (np.abs(y_test) + np.abs(y_pred) + 1e-8)\n",
    ") * 100\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "print(f\"WMAPE: {wmape:.2f}%\")\n",
    "print(f\"SMAPE: {smape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3ccc3-231e-4687-8f5e-94780e9e4193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
